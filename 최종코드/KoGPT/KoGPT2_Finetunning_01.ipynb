{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KoGPT2_Finetunning_01.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOYdHm6u8xOeeFrRfxfRXaX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXdVKqMzWrYT","executionInfo":{"status":"ok","timestamp":1636097753359,"user_tz":-540,"elapsed":21602,"user":{"displayName":"JeongBeom Cho","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719327316927255470"}},"outputId":"fce68935-2e06-4470-f0b6-678edb9d98c2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"d6Wcaa2HXPrz"},"source":["!pip install transformers\n","!pip install datasets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuh7k2OZdwLa"},"source":["# import re\n","# df = pd.read_csv('/content/drive/MyDrive/데이터/명언 홈페이지_크롤링(1~600페이지-전처리완료).txt')\n","# df['내용'] = df['내용'].apply(lambda x: re.sub('[^ㄱ-ㅎㅏ-ㅣ-가-힣0-9. ]', '', str(x)))\n","# df.to_csv('/content/drive/MyDrive/데이터/명언 홈페이지_크롤링(1~600페이지-전처리완료).txt', index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"raRPXfymWJBd"},"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import GPT2LMHeadModel\n","from transformers import Trainer, TrainingArguments\n","from transformers import PreTrainedTokenizerFast\n","\n","def load_dataset(file_path, tokenizer, block_size = 128):\n","    dataset = TextDataset(\n","        tokenizer = tokenizer,\n","        file_path = file_path,\n","        block_size = block_size,\n","    )\n","    return dataset\n","\n","def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer = tokenizer,\n","        mlm = mlm,\n","    )\n","    return data_collator\n","\n","def train(train_file_path, model_name, output_dir, overwrite_output_dir,\n","          per_device_train_batch_size, num_train_epochs, save_steps):\n","    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name,\n","                bos_token = '</s>', eos_token = '</s>', unk_token = '<unk>',\n","                pad_token = '<pad>', mask_token = '<mask>')\n","    train_dataset = load_dataset(train_file_path, tokenizer)\n","    data_collator = load_data_collator(tokenizer)\n","\n","    tokenizer.save_pretrained(output_dir, legacy_format = False)\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","    model.save_pretrained(output_dir)\n","\n","    training_args = TrainingArguments(\n","        output_dir = output_dir,\n","        overwrite_output_dir = overwrite_output_dir,\n","        per_device_eval_batch_size = per_device_train_batch_size,\n","        num_train_epochs = num_train_epochs,\n","    )\n","\n","    trainer = Trainer(\n","        model = model,\n","        args = training_args,\n","        data_collator = data_collator,\n","        train_dataset = train_dataset,\n","    )\n","\n","    trainer.train()\n","    trainer.save_model()\n","\n","train_file_path = '/content/drive/MyDrive/데이터/명언 홈페이지_크롤링(전처리완료).txt'\n","model_name = 'skt/kogpt2-base-v2'\n","output_dir = '/content/drive/MyDrive/Colab Notebooks/팀프로젝트/빅데이터 지능형 서비스과정(최종프로젝트)/KoGPT2_FineTunning(Wise)'\n","overwrite_output_dir = False\n","per_device_train_batch_size = 8\n","num_train_epochs = 20.0\n","save_steps = 500\n","\n","train(train_file_path = train_file_path,\n","      model_name = model_name,\n","      output_dir = output_dir,\n","      overwrite_output_dir = overwrite_output_dir,\n","      per_device_train_batch_size = per_device_train_batch_size,\n","      num_train_epochs = num_train_epochs,\n","      save_steps = save_steps\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0imqGOJBZIj"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qamM72nkBZrg"},"source":["df = pd.read_csv('/content/drive/MyDrive/데이터/명언 홈페이지_크롤링(전처리완료).csv')\n","df['한글명언'] = df['명언'].apply(lambda x: x.split('\\n')[0])\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7Q8f_4YCGMV"},"source":["df['시작문'] = ['값 없음' for _ in range(len(df['한글명언']))]\n","for i in range(len(df['한글명언'])):\n","    if len(df['한글명언'][i].split(' ')) >= 3:\n","        df['시작문'][i] = df['한글명언'][i].split(' ')[0] + ' ' + df['한글명언'][i].split(' ')[1] + ' ' + df['한글명언'][i].split(' ')[2]\n","    elif len(df['한글명언'][i].split(' ')) >= 2:\n","        df['시작문'][i] = df['한글명언'][i].split(' ')[0] + ' ' + df['한글명언'][i].split(' ')[1]\n","    else:\n","        df['시작문'][i] = df['한글명언'][i].split(' ')[0]\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zM81MaYCNJM","executionInfo":{"status":"ok","timestamp":1635990148947,"user_tz":-540,"elapsed":6,"user":{"displayName":"JeongBeom Cho","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719327316927255470"}},"outputId":"4d2c4a0d-7461-4883-c725-63ad90912965"},"source":["start_word = list(set(list(df['시작문'])))[1:] \n","df['첫문장'] = df['한글명언'].apply(lambda x: x.split('.')[0])\n","start_sentence = list(set(list(df['첫문장']))) \n","len(start_word), len(start_sentence)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13198, 13284)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUOjTytuCc1P","executionInfo":{"status":"ok","timestamp":1635990149514,"user_tz":-540,"elapsed":571,"user":{"displayName":"JeongBeom Cho","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719327316927255470"}},"outputId":"f44cf15c-62c6-4029-f608-fe0f57c82c5f"},"source":["import random\n","n = random.randint(0, len(start_word))\n","start_word[n], start_sentence[n]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('사랑은 상실이며 단념이다.', '인간의 미래는 인간의 마음에 있다')"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"5D3B5A6Oam7g"},"source":["from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","from tqdm.notebook import tqdm\n","\n","def load_model(model_path):\n","  model = GPT2LMHeadModel.from_pretrained(model_path)\n","  return model\n","\n","def load_tokenizer(tokenizer_path):\n","  tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n","  return tokenizer\n","\n","def generate_text(sequence, max_lenth):\n","  model_path = '/content/drive/MyDrive/Colab Notebooks/팀프로젝트/빅데이터 지능형 서비스과정(최종프로젝트)/KoGPT2_FineTunning(Wise)'\n","  model = load_model(model_path)\n","  tokenizer = load_tokenizer(model_path)\n","  ids = tokenizer.encode(f'{sequence},', return_tensors = 'pt')\n","  final_outputs = model.generate(\n","      ids,\n","      do_sample = True,\n","      max_length = max_length,\n","      pad_token_id = model.config.pad_token_id,\n","      tok_k = 25,\n","      top_p = 0.90,\n","      repetition_penalty = 1.5,\n","  )\n","  return tokenizer.decode(final_outputs[0])\n","  # return tokenizer.decode(final_outputs[0], skip_special_tokens = True)\n","\n","import random\n","n = random.randint(0, len(start_word))\n","sequence = '11월 4일에 헬스장에 가서 운동을 했다.'\n","# sequence = df['한글명언'][n]\n","refer = df['인물'][n]\n","# sequence = start_sentence[n]\n","max_length = 256 \n","sentence_list = []\n","print('input : ' + sequence + ' ' + refer)\n","# for i in tqdm(range(5)):\n","sentence_list.append(generate_text(sequence, max_length))\n","sentence = generate_text(sequence, max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yfyt4QjoV3YV","executionInfo":{"status":"ok","timestamp":1635991605829,"user_tz":-540,"elapsed":447,"user":{"displayName":"JeongBeom Cho","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719327316927255470"}},"outputId":"50e2e6bd-47a3-45ba-e02a-1f2c28e27fb2"},"source":["# sentence_extract_one_list1 = []\n","# sentence_extract_one_list2 = []\n","# for i in range(5):\n","#   sentence_list[i] = sentence_list[i].replace('\\n', ' ')\n","#   sentence_extract_one_list1.append(sentence_list[i].split('.')[0] + '.' + sentence_list[i].split('.')[1] + '.')\n","#   sentence_extract_one_list2.append(sentence_list[i].split(', ')[1])\n","# sentence_extract_one_list1 # 2~3개 단어단위 입력시 가공\n","# sentence_extract_one_list2 # 문장단위 입력시 가공\n","\n","# ch_sentence = sentence.split(sequence + ', ')[1:]\n","# ch_sentence_list = ch_sentence[0].split('\\n')\n","# print(f'입력문장 : {sequence}')\n","# for i in range(len(ch_sentence_list)):\n","#   print(f'출력문장{i+1} : {ch_sentence_list[i]}')\n","\n","ch_sentence = sentence.split('sequence' + ', ')\n","ch_sentence_list = ch_sentence[0].split('\\n')[1:]\n","print(f'입력 명언 : {sequence} {refer}')\n","for i in range(len(ch_sentence_list)):\n","  print(f'출력 문장 : {ch_sentence_list[i]}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 명언 : 11월 4일에 헬스장에 가서 운동을 했다. 커트 코베인\n","출력 문장 : 타인의 권리는 권력이나 부에 의하지 않고는 가질 수 없다. 그러나 타인의 권리의리는 존중되어야 한다.\n","출력 문장 : 인생은 투쟁과 변화와 단호한 결정으로 다져진다.\n","출력 문장 : 삶은 타협할 수가 없어요. 서로가 익숙해져버린 삶에 대해 고통스러워지는 거죠.\n","출력 문장 : 다들 행복해 질거야. 그러니까 시작만 하고 끝나는게 아니라 여러분이 만들어 놓은 일상의 모습에 놀라워 하죠. 그 모든 것에 일일이 손을 대지 않아도 돼요.\n","출력 문장 : 이 세상에 있는 그대로의 모습으로 당신 자신을 볼 수는 없습니다. 당신의 모습이 되어 다른 사람들의 모습을 보고 있을 수도 있고 또 그런 경험을 통해 다시 자신의 모습 변화를 시도 할수도 있습니다. 하지만 이러한 활동들은 자신만의 방식으로 미 사회를 변화시킬수는 없습니다.\n","출력 문장 : 중요한건 삶을 살아갈 힘을 얻는 일이란 아니다. 인간은 무엇인가를 해야 한다. 무엇을 먹느냐에 대한 우리의 의지이다.\n","출력 문장 : 자신을 극복하는 힘이 생긴다.\n","출력 문장 : 무엇을 잘 하는 건 어렵지만 그것을 즐기는 것만으로는 부족하다. 남에게 행복을 느끼게 되는 법을 알지 못하는 인생이 필요하다.\n","출력 문장 : 시도하지 않는 삶은 즐거운 것이다.\n","출력 문장 : 하루를 유익하게 보낸다는 것은 얼마나 큰 가치가 있다. 한 번 뿐이다.\n","출력 문장 : 평화는 두 사람 모두가 행복한 인생을 만든다.\n","출력 문장 : 웃음은 작은 웃음 속에 있다.\n","출력 문장 : 잘 견디기엔 많은 말이다. 한번밖에 없다.\n","출력 문장 : 사랑하는 데 1년 걸음을 짧게 느껴진다.\n","출력 문장 : 진 열 남을 웃지 마라.\n","출력 문장 : 두 마음에는 오래 가지 말라\n"]}]}]}