{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KoGPT2_Finetunning_02(브런치-일기).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNV5r0XCqzSB5SAdMBJdJNO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMRxBL-36iUd","executionInfo":{"status":"ok","timestamp":1636505129976,"user_tz":-540,"elapsed":3012,"user":{"displayName":"JeongBeom Cho","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719327316927255470"}},"outputId":"e585e857-efe4-4514-86ed-ce24d13e5906"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"ecZBqye06qLF"},"source":["!pip install transformers\n","!pip install datasets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SeOZ1ZU27Bu2"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l5QRwIFb7Hz_"},"source":["# df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/팀프로젝트/빅데이터 지능형 서비스과정(최종프로젝트)/KoGPT2_FineTunning/Branch(일기)/Data/Crawling(brunch_일기_10291개).txt')\n","# df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eGPQP5J7JSrg"},"source":["df['내용'][10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzXED-KuGGef"},"source":["# df['내용'] = df['내용'].apply(lambda x : str(x).replace('\\n', ' '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('.', '. '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace(',', ', '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('\"', ''))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace(\"'\", ''))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('?', '? '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('!', '! '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('  ', ' '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('  ', ' '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('  ', ' '))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nkdrSrCtHrmH"},"source":["# import re\n","# df['내용'] = df['내용'].apply(lambda x : re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣A-Za-z0-9()., ]', '', x))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace(' .', ' '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('  ', ' '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('  ', ' '))\n","# df['내용'] = df['내용'].apply(lambda x : str(x).replace('  ', ' '))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"naTBhFfGGhRc"},"source":["# df['내용'][30]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwMxlz2jJtao"},"source":["# df['내용'].to_csv('/content/drive/MyDrive/Colab Notebooks/팀프로젝트/빅데이터 지능형 서비스과정(최종프로젝트)/KoGPT2_FineTunning/Branch(일기)/Data/Crawling(brunch_일기_10289개_전처리완료).txt', index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbSO1sA6J6Y1"},"source":["# pd.read_csv('/content/drive/MyDrive/Colab Notebooks/팀프로젝트/빅데이터 지능형 서비스과정(최종프로젝트)/KoGPT2_FineTunning/Branch(일기)/Data/Crawling(brunch_일기_10289개_전처리완료).txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M76ebr4U6til"},"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import GPT2LMHeadModel\n","from transformers import Trainer, TrainingArguments\n","from transformers import PreTrainedTokenizerFast\n","\n","def load_dataset(file_path, tokenizer, block_size = 128):\n","    dataset = TextDataset(\n","        tokenizer = tokenizer,\n","        file_path = file_path,\n","        block_size = block_size,\n","    )\n","    return dataset\n","\n","def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer = tokenizer,\n","        mlm = mlm,\n","    )\n","    return data_collator\n","\n","def train(train_file_path, model_name, output_dir, overwrite_output_dir,\n","          per_device_train_batch_size, num_train_epochs, save_steps):\n","    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name,\n","                bos_token = '</s>', eos_token = '</s>', unk_token = '<unk>',\n","                pad_token = '<pad>', mask_token = '<mask>')\n","    train_dataset = load_dataset(train_file_path, tokenizer)\n","    data_collator = load_data_collator(tokenizer)\n","\n","    tokenizer.save_pretrained(output_dir, legacy_format = False)\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","    model.save_pretrained(output_dir)\n","\n","    training_args = TrainingArguments(\n","        output_dir = output_dir,\n","        overwrite_output_dir = overwrite_output_dir,\n","        per_device_eval_batch_size = per_device_train_batch_size,\n","        num_train_epochs = num_train_epochs,\n","    )\n","\n","    trainer = Trainer(\n","        model = model,\n","        args = training_args,\n","        data_collator = data_collator,\n","        train_dataset = train_dataset,\n","    )\n","\n","    trainer.train()\n","    trainer.save_model()\n","\n","train_file_path = '/content/drive/MyDrive/Colab Notebooks/팀프로젝트/빅데이터 지능형 서비스과정(최종프로젝트)/KoGPT2_FineTunning/Branch(일기)/Data/Crawling(brunch_일기_10289개_전처리완료).txt'\n","model_name = 'skt/kogpt2-base-v2'\n","output_dir = '/content/drive/MyDrive/Colab Notebooks/팀프로젝트/빅데이터 지능형 서비스과정(최종프로젝트)/KoGPT2_FineTunning/Branch(일기)/모델2(10289개 학습)'\n","overwrite_output_dir = False\n","per_device_train_batch_size = 8\n","num_train_epochs = 50.0\n","save_steps = 500\n","\n","train(train_file_path = train_file_path,\n","      model_name = model_name,\n","      output_dir = output_dir,\n","      overwrite_output_dir = overwrite_output_dir,\n","      per_device_train_batch_size = per_device_train_batch_size,\n","      num_train_epochs = num_train_epochs,\n","      save_steps = save_steps\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cb2w7_Fe9Sb-"},"source":["from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","from tqdm.notebook import tqdm\n","\n","def load_model(model_path):\n","  model = GPT2LMHeadModel.from_pretrained(model_path)\n","  return model\n","\n","def load_tokenizer(tokenizer_path):\n","  tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n","  return tokenizer\n","\n","def generate_text(sequence, max_lenth):\n","  model_path = '/content/drive/MyDrive/Colab Notebooks/팀프로젝트/빅데이터 지능형 서비스과정(최종프로젝트)/KoGPT2_FineTunning/Branch(일기)'\n","  model = load_model(model_path)\n","  tokenizer = load_tokenizer(model_path)\n","  ids = tokenizer.encode(f'{sequence},', return_tensors = 'pt')\n","  final_outputs = model.generate(\n","      ids,\n","      do_sample = True,\n","      max_length = max_length,\n","      pad_token_id = model.config.pad_token_id,\n","      top_k = 1,\n","      top_p = 0.90,\n","      repetition_penalty = 1.5,\n","  )\n","  return tokenizer.decode(final_outputs[0])\n","  # return tokenizer.decode(final_outputs[0], skip_special_tokens = True)\n","\n","sequence = '즐거움 피자 맥주'\n","max_length = 256\n","sentence_list = []\n","# print('input : ' + sequence + ' ' + refer)\n","# for i in tqdm(range(5)):\n","sentence_list.append(generate_text(sequence, max_length))\n","sentence = generate_text(sequence, max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7n_Y3zu09Y11"},"source":["ch_sentence = sentence.split(sequence + ', ')[1:]\n","print(f'입력 값 : {sequence}')\n","# ch_sentence = ch_sentence[0].replace(',', ' ')\n","ch_sentence = ch_sentence[0].replace('\\n', ' ')\n","ch_sentence = ch_sentence.replace('.', '. ')\n","ch_sentence = ch_sentence.replace('\"', '')\n","ch_sentence = ch_sentence.replace('<unk>', '')\n","ch_sentence = ch_sentence.replace('?', '? ')\n","ch_sentence = ch_sentence.replace('!', '! ')\n","ch_sentence = ch_sentence.replace('  ', ' ')\n","ch_sentence = ch_sentence.replace('  ', ' ')\n","ch_sentence = ch_sentence.replace('  ', ' ')\n","ch_sentence"],"execution_count":null,"outputs":[]}]}